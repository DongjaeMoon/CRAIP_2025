import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import String, Float32
from cv_bridge import CvBridge
import message_filters
import cv2
from ultralytics import YOLO
import numpy as np
import os
from ament_index_python.packages import get_package_share_directory

class PerceptionNode(Node):
    def __init__(self):
        super().__init__('perception_node')

        # 1. ëª¨ë¸ ê²½ë¡œ ì„¤ì • (setup.pyì—ì„œ ë³µì‚¬ëœ ìœ„ì¹˜ë¥¼ ìë™ìœ¼ë¡œ ì°¾ìŒ)
        package_share_directory = get_package_share_directory('perception')
        model_path = os.path.join(package_share_directory, 'weights', 'best(1).pt')

        

        self.get_logger().info(f'Loading YOLO model from: {model_path}')
        try:
            self.model = YOLO(model_path)
        except Exception as e:
            self.get_logger().error(f"Failed to load model: {e}")
            # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì•ˆì „ì¥ì¹˜ (ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)
            self.model = YOLO("yolov8n.pt")

        # 2. Publishers
        self.pub_image = self.create_publisher(Image, '/camera/detections/image', 10)
        self.pub_label = self.create_publisher(String, '/detections/labels', 10)
        self.pub_dist = self.create_publisher(Float32, '/detections/distance', 10)
        self.pub_speech = self.create_publisher(String, '/robot_dog/speech', 10)

        # 3. Subscribers (Time Synchronizer)
        self.br = CvBridge()
        
        # í† í”½ ì´ë¦„ í™•ì¸ í•„ìˆ˜! (Depthì™€ Imageê°€ ì§ì´ ë§ì•„ì•¼ í•¨)
        rgb_sub = message_filters.Subscriber(self, Image, '/camera_top/image')
        depth_sub = message_filters.Subscriber(self, Image, '/camera_top/depth')

        # ë‘ ì´ë¯¸ì§€ì˜ ì‹œê°„ì„ ë§ì¶°ì£¼ëŠ” ë™ê¸°í™” ë„êµ¬ (slop=0.1ì´ˆ ì˜¤ì°¨ í—ˆìš©)
        ts = message_filters.ApproximateTimeSynchronizer([rgb_sub, depth_sub], 10, 0.1)
        ts.registerCallback(self.listener_callback)
        
        self.get_logger().info("Perception Node Started! Waiting for images...")

    def listener_callback(self, rgb_msg, depth_msg):
        self.get_logger().info("ğŸ“· ì´ë¯¸ì§€ ìˆ˜ì‹  ì„±ê³µ! (Callback Working)")
        # 1. ì´ë¯¸ì§€ ë³€í™˜
        try:
            frame = self.br.imgmsg_to_cv2(rgb_msg, "bgr8")
            depth_frame = self.br.imgmsg_to_cv2(depth_msg, "32FC1") # ë¯¸í„° ë‹¨ìœ„ (Float32)
        except Exception as e:
            self.get_logger().error(f"Image conversion error: {e}")
            return

        img_h, img_w, _ = frame.shape

        # 2. YOLO ì¶”ë¡ 
        results = self.model(frame, verbose=False)
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        final_label = "None"
        final_dist = 0.0
        speech_cmd = "None"
        
        # ê°ì§€ëœ ë¬¼ì²´ ì²˜ë¦¬
        for result in results:
            boxes = result.boxes
            for box in boxes:
                # ì¢Œí‘œ ë° ì •ë³´ ì¶”ì¶œ
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cls = int(box.cls[0])
                conf = float(box.conf[0])
                label_name = self.model.names[cls] # ì˜ˆ: fresh_apple, rotten_banana

                # ì¤‘ì‹¬ì  ê³„ì‚°
                cx = (x1 + x2) // 2
                cy = (y1 + y2) // 2

                # 3. ê±°ë¦¬ ì¸¡ì • (Depth ì´ë¯¸ì§€ì—ì„œ ì¤‘ì‹¬ì ì˜ ê¹Šì´ê°’ ì½ê¸°)
                # ì¢Œí‘œê°€ ì´ë¯¸ì§€ ë°–ìœ¼ë¡œ ë‚˜ê°€ì§€ ì•Šê²Œ ë³´í˜¸
                cx_safe = np.clip(cx, 0, img_w - 1)
                cy_safe = np.clip(cy, 0, img_h - 1)
                
                real_dist = depth_frame[cy_safe, cx_safe]

                # ê±°ë¦¬ê°’ì´ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´(inf, nan) ë¬´ì‹œ
                if np.isnan(real_dist) or np.isinf(real_dist):
                    continue

                # 4. íŒë‹¨ ë¡œì§ (Rule)
                # A. ê±°ë¦¬ ì¡°ê±´: 3m ì´ë‚´
                is_close = real_dist <= 3.0
                
                # B. ìœ„ì¹˜ ì¡°ê±´: ê°€ë¡œì˜ ê°€ìš´ë° 3/5 ì˜ì—­ (0.2 ~ 0.8)
                left_limit = img_w * 0.2
                right_limit = img_w * 0.8
                is_centered = left_limit < cx < right_limit
                
                # C. ì¢…ë¥˜ ì¡°ê±´: 'fresh'ê°€ ë“¤ì–´ê°„ ì´ë¦„ë§Œ ì‹ìš© (fresh_apple ë“±)
                is_edible = "good" in label_name

                # ì‹œê°í™” (ë°•ìŠ¤ ê·¸ë¦¬ê¸°)
                color = (0, 255, 0) if is_edible else (0, 0, 255) # ì‹ìš©ì€ ì´ˆë¡, ì•„ë‹ˆë©´ ë¹¨ê°•
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                cv2.putText(frame, f"{label_name} {real_dist:.2f}m", (x1, y1-10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

                # â˜… BARK ì¡°ê±´ ì²´í¬ â˜…
                if is_edible and is_close and is_centered:
                    speech_cmd = "bark"
                    final_label = label_name
                    final_dist = float(real_dist)
                    
                    # ì§–ëŠ” ìƒí™© ì‹œê°í™” (í™”ë©´ì— í…ìŠ¤íŠ¸ í‘œì‹œ)
                    cv2.putText(frame, "BARK!!!", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 
                                1.5, (0, 255, 255), 3)

        # 5. ê²°ê³¼ ë°œí–‰ (Publish)
        self.pub_image.publish(self.br.cv2_to_imgmsg(frame, "bgr8"))
        
        msg_label = String()
        msg_label.data = final_label
        self.pub_label.publish(msg_label)

        msg_dist = Float32()
        msg_dist.data = final_dist
        self.pub_dist.publish(msg_dist)

        msg_speech = String()
        msg_speech.data = speech_cmd
        self.pub_speech.publish(msg_speech)

def main(args=None):
    rclpy.init(args=args)
    node = PerceptionNode()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
